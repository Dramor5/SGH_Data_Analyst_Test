altered_pie_df <- categorical_df %>%
gather(key = 'category') %>%
count(category, value) %>%
mutate(perc_n = round(n/nrow(categorical_df)*100, 2))
# Create pie charts for every categorical variable.
for (i in unique(altered_pie_df$category)) {
p <- altered_pie_df[altered_pie_df$category == i, ] %>%
ggplot(aes(x="", y=n, fill=value)) +
geom_col(color = 'black') +
geom_text(aes(label = paste(perc_n, '%')),
position = position_stack(vjust = 0.5)) +
coord_polar("y", start=0) +
theme_void() +
ggtitle(paste(i)) +
theme(plot.title = element_text(hjust = 0.5))
print(p)
}
# Prepare dataframe for plotting venn diagram.
pDM_or_DM_venn <- categorical_df %>%
select(dx, gh) %>%
# Filter for row sums >= 1 to exclude individuals who are not in either category. (Not diabetic, not preDM)
filter(rowSums(.) >= 1) %>%
# Transform into T/F for venn diagram plotting.
mutate(dx = as.logical(dx),
gh = as.logical(gh)) %>%
rename('preDM or DM' = dx,
'DM' = gh)
# Plot the venn diagram.
ggvenn(pDM_or_DM_venn, c('preDM or DM', 'DM'))
# The individual's diabetes status is more clearly illustrated below.
# dx = 0, gh = 0 -> no preDM or DM
# dx = 1, gh = 1 -> DM
# dx = 1, gh = 0 -> preDM
# dx = 0, gh = 1 -> DM
# Load data with only continuous variables.
query <- 'SELECT age, wt, ht, bmi, leg, arml, armc, waist, tri, sub, gh, albumin, bun, SCr FROM diabetes_data'
continuous_df <- dbGetQuery(conn, query)
# Remove NAs, add a categorical variable `diabetes` containing diabetic labels.
continuous_df <- continuous_df %>%
na.omit() %>%
mutate(diabetes = case_when(gh >= 6.5 ~ 1,
T ~ 0))
# Produce a correlation matrix from a dataframe (Pearson's correlation coefficient).
cont_heatmap <- cor(continuous_df)
pheatmap(cont_heatmap,
display_numbers = T)
# Plot all continuous variables against gh.
for (i in colnames(continuous_df)) {
p <- ggplot(continuous_df) +
geom_point(aes_string(x = i, y = 'gh', col = 'diabetes')) +
theme_classic()
print(p)
}
# Initialize a new list for result collection.
t_test_df <- list()
# For all continuous variables except the diabetes columns, do a t-test of means between diabetics and non-diabetics.
for (i in colnames(continuous_df)[1:length(colnames(continuous_df)) - 1]) {
# Perform the t-test.
t_res <- t.test(continuous_df[continuous_df$diabetes == 1, colnames(continuous_df) == i],
continuous_df[continuous_df$diabetes == 0, colnames(continuous_df) == i])
# Collect results into a list.
entry <- list('col_name' = i,
'p_value' = t_res$p.value,
'diabetic_mean' = round(t_res$estimate[[1]],2),
'non_diabetic_mean' = round(t_res$estimate[[2]], 2))
# Add the entry into a list.
t_test_df[[i]] <- entry
}
# R-bind all lists to form a dataframe.
t_test_df <- rbindlist(t_test_df) %>%
arrange(p_value) %>%
mutate(significant = case_when(p_value < 0.05 ~ T,
T ~ F))
t_test_df
# Obtain categorical variables and gh.
query <- 'SELECT sex, re, income, tx, dx, gh FROM diabetes_data'
categorical_df <- dbGetQuery(conn, query) %>%
mutate(diabetes = case_when(gh >= 6.5 ~ T,
T ~ F)) %>%
select(-gh)
# Initialize empty list.
chi_sq_df <- list()
# For all columns except the diabetes marker, perform chi square test.
# Determine if variable in question is significantly associated with diabetes.
for (i in colnames(categorical_df)[1:length(colnames(categorical_df)) - 1]) {
# Construct contingency table, perform chi square test.
cont_table <- table(categorical_df[[i]], categorical_df$diabetes)
chi_squared_result <- chisq.test(cont_table)
cramers_v_result <- assocstats(cont_table)
# Store result in a list.
entry <- list('col_name' = i,
'chi-sq_stat' = chi_squared_result$statistic,
'p_value' = chi_squared_result$p.value,
'cramers_v' = cramers_v_result$cramer)
chi_sq_df[[i]] <- entry
}
# R-bind all lists to form a dataframe.
chi_sq_df <- rbindlist(chi_sq_df) %>%
arrange(p_value) %>%
mutate(significant = case_when(p_value < 0.05 ~ T,
T ~ F))
chi_sq_df
# Load data.
query <- 'SELECT * FROM diabetes_data'
df <- dbGetQuery(conn, query)
dbDisconnect(conn) # SQL is no longer used after this.
# Perform KNN imputation.
after_impute_df <- df %>%
kNN(variable = 'albumin',
k = 5) %>%
rename('albumin_imputed' = albumin_imp)
# Plot new distribution.
alb_after_plot <- ggplot(after_impute_df) +
geom_point(aes(x = albumin, y = gh, col = albumin_imputed))
alb_after_plot
print(paste('albumin NA values before imputation:', sum(is.na(df$albumin))))
print(paste('albumin NA values after imputation:', sum(is.na(after_impute_df$albumin))))
summary(df$albumin)
summary(after_impute_df$albumin)
after_impute_df <- after_impute_df %>%
select(age, bmi, albumin, tx, dx, gh) %>%
mutate(diabetes = case_when(gh >= 6.5 ~ 1,
T ~ 0),
diabetes = as.factor(diabetes)) %>%
select(-gh)
# Count number of rows after imputation.
print(paste('Total number of rows:', nrow(after_impute_df)))
# Filter out individuals below the age of 20.
after_impute_df_filtered <- after_impute_df %>%
filter(age > 20)
# Count number of rows after filtration.
print(paste('Total number of rows:', nrow(after_impute_df_filtered)))
# Split dataset in a 70:30 train:test ratio.
split <- sample.split(after_impute_df_filtered, SplitRatio = 0.7)
train_df <- subset(after_impute_df_filtered, split == T)
test_df <- subset(after_impute_df_filtered, split == F)
# Construct control variable for log regression model, for k-fold cross validation.
log_control <- trainControl(method = 'cv', number = 10)
# Build a logistic regression model.
log_model <- train(diabetes ~ ., data = train_df, method = "glm", family = "binomial", trControl = log_control)
log_model
# Collect results of model's coefficients and exponentiated coefficients in a dataframe.
coeffs <- rbind(
log_model$finalModel$coefficients,
exp(log_model$finalModel$coefficients)
) %>%
round(.,4) %>%
cbind(value = c('coefficient', 'exponentiated_coefficient')) %>%
as.data.frame()
coeffs
# Use model on test data.
log_predictions <- predict(log_model,
newdata = test_df)
log_results <- confusionMatrix(log_predictions, test_df$diabetes, positive = '1')
# Optimize cp value for decision trees.
control <- trainControl(method = "repeatedcv",
number = 10,
search = "grid")
decision_tree <- train(diabetes ~ ., data = train_df, 'rpart', trControl = control)
decision_tree
# Visualize the optimized model.
rpart.plot(decision_tree$finalModel)
# Use the model to predict diabetic labels.
decision_tree_predictions <- predict(decision_tree, newdata = test_df)
tree_results <- confusionMatrix(decision_tree_predictions,
test_df$diabetes,
positive = '1')
# Create and visualize a more complex tree. Use rpart to manually specify cp value
decision_tree_low_cp <- rpart(diabetes ~ ., data = train_df, cp = 0.0036)
rpart.plot(decision_tree_low_cp)
# Create random forest model.
rf <- train(diabetes ~ .,
data = train_df,
method = 'rf',
trControl = control)
rf
# Take the mean of all error rates, multiply by 100.
paste('Out of bag estimate of error rate:',
round(mean(rf$finalModel$err.rate[,1]), 2)*100,
'%',
sep = ' ')
# Use the model to make predictions on diabetic labels.
rf_predictions <- predict(rf, test_df)
rf_predictions <- as.factor(rf_predictions)
rf_results <- confusionMatrix(rf_predictions, test_df$diabetes, positive = '1')
# Result compilation.
# Bind all results into a dataframe.
combined_results <- rbind(
'Logistic regression' = unlist(log_results),
'Decision tree' = unlist(tree_results),
'Random forest' = unlist(rf_results)
) %>%
as.data.frame() %>%
# Remove all column prefixes.
# ^[^.]+ From the start of the string, detect any number of characters that is not a full stop.
# \\. Match a fullstop (\\ is used to escape the fullstop).
rename_all( ~ gsub("^[^.]+\\.", "", .)) %>%
# Select relevant columns.
select(Accuracy,
Sensitivity,
Specificity,
Precision,
`Neg Pred Value`,
F1) %>%
# Convert values from character to float (double), round to 4 digits after decimal points.
mutate_all(as.double) %>%
round(., 4) %>%
gt()
combined_results
knitr::opts_chunk$set(echo = TRUE)
# Define a relative path to a file or directory
relative_path <- file.path('Data', 'nhgh.tsv')
image_path <- file.path('Images','data_dictionary.png')
# Load packages
library(tidyverse)
library(ggplot2)
library(DBI)
library(naniar)
library(GGally)
library(reshape2)
library(data.table)
library(pheatmap)
library(vcd)
library(ggvenn)
library(VIM)
library(gridExtra)
library(caTools)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(gt)
# Setting global seed for reproducibility
set.seed(777)
# Loading of data.
df <- read_tsv(relative_path,
show_col_types = FALSE)
# Check for duplications in seqn.
sum(duplicated(df$seqn))
# Open a SQLite connection.
conn <- dbConnect(RSQLite::SQLite(), dbname = 'diabetes.db')
# dbRemoveTable(conn,'diabetes_data')
# dbRemoveTable(conn,'diabetes_data_modified')
# Create a new table within the database.
dbWriteTable(conn,
name = 'diabetes_data',
value = df,
overwrite = TRUE)
# Analyze the whole dataset first.
query <- 'SELECT * FROM diabetes_data'
df <- dbGetQuery(conn, query)
# Produce an NA plot.
na_plot <- vis_miss(df)
print(na_plot)
# Look at unique combinations of missing data.
aggr(df)
# Count the number of entries.
query <- "SELECT COUNT(*) FROM diabetes_data"
initial_row_count <- dbGetQuery(conn, query)
print(paste('Initial row count:', initial_row_count))
# Count number of entries with atleast one NA in them.
query <- "SELECT COUNT(*) FROM diabetes_data WHERE income iS NULL OR leg IS NULL OR arml IS NULL OR armc IS NULL OR waist IS NULL OR tri IS NULL OR sub IS NULL OR albumin IS NULL OR bun IS NULL OR Scr IS NULL"
row_count_no_NA <- dbGetQuery(conn, query)
print(paste('Rows with atleast one NA:', row_count_no_NA))
# Calculate the amount of data lost.
print(paste('Percent data lost: ', round(row_count_no_NA/initial_row_count*100), '%', sep = ''))
# Obtain continuous variables.
query <- 'SELECT age, wt, ht, bmi, leg, arml, armc, waist, tri, sub, gh, albumin, bun, SCr FROM diabetes_data'
continuous_df <- dbGetQuery(conn, query)
# Transform into a two col dataframe of variables and values. This is necessary for facet_wrap().
continuous_df_long <- melt(continuous_df)
# For each variable, plot a violin+boxplot.
continuous_plot <- ggplot(continuous_df_long, aes(x = variable, y = value)) +
geom_violin(width = 1) +
geom_boxplot(width = 0.5) +
facet_wrap(~ variable, scales = "free") +
theme_classic()
continuous_plot
summary(continuous_df)
# Obtain categorical variables and gh.
query <- 'SELECT sex, re, income, tx, dx, gh FROM diabetes_data'
categorical_df <- dbGetQuery(conn, query)
# Transform gh to categorical variable.
categorical_df <- categorical_df %>%
mutate(gh = case_when(gh >= 6.5 ~ 1,
T ~ c(0)))
# Create bar plots.
for (i in colnames(categorical_df)) {
if (i == 'income') {
p <- ggplot(categorical_df) +
geom_bar(aes_string(x = i)) +
theme_classic() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
print(p)
}
else {
p <- ggplot(categorical_df) +
geom_bar(aes_string(x = i)) +
theme_classic()
print(p)
}
}
# Transform into long format, for all categories, count all values observed.
altered_pie_df <- categorical_df %>%
gather(key = 'category') %>%
count(category, value) %>%
mutate(perc_n = round(n/nrow(categorical_df)*100, 2))
# Create pie charts for every categorical variable.
for (i in unique(altered_pie_df$category)) {
p <- altered_pie_df[altered_pie_df$category == i, ] %>%
ggplot(aes(x="", y=n, fill=value)) +
geom_col(color = 'black') +
geom_text(aes(label = paste(perc_n, '%')),
position = position_stack(vjust = 0.5)) +
coord_polar("y", start=0) +
theme_void() +
ggtitle(paste(i)) +
theme(plot.title = element_text(hjust = 0.5))
print(p)
}
# Prepare dataframe for plotting venn diagram.
pDM_or_DM_venn <- categorical_df %>%
select(dx, gh) %>%
# Filter for row sums >= 1 to exclude individuals who are not in either category. (Not diabetic, not preDM)
filter(rowSums(.) >= 1) %>%
# Transform into T/F for venn diagram plotting.
mutate(dx = as.logical(dx),
gh = as.logical(gh)) %>%
rename('preDM or DM' = dx,
'DM' = gh)
# Plot the venn diagram.
ggvenn(pDM_or_DM_venn, c('preDM or DM', 'DM'))
# The individual's diabetes status is more clearly illustrated below.
# dx = 0, gh = 0 -> no preDM or DM
# dx = 1, gh = 1 -> DM
# dx = 1, gh = 0 -> preDM
# dx = 0, gh = 1 -> DM
# Load data with only continuous variables.
query <- 'SELECT age, wt, ht, bmi, leg, arml, armc, waist, tri, sub, gh, albumin, bun, SCr FROM diabetes_data'
continuous_df <- dbGetQuery(conn, query)
# Remove NAs, add a categorical variable `diabetes` containing diabetic labels.
continuous_df <- continuous_df %>%
na.omit() %>%
mutate(diabetes = case_when(gh >= 6.5 ~ 1,
T ~ 0))
# Produce a correlation matrix from a dataframe (Pearson's correlation coefficient).
cont_heatmap <- cor(continuous_df)
pheatmap(cont_heatmap,
display_numbers = T)
# Plot all continuous variables against gh.
for (i in colnames(continuous_df)) {
p <- ggplot(continuous_df) +
geom_point(aes_string(x = i, y = 'gh', col = 'diabetes')) +
theme_classic()
print(p)
}
# Initialize a new list for result collection.
t_test_df <- list()
# For all continuous variables except the diabetes columns, do a t-test of means between diabetics and non-diabetics.
for (i in colnames(continuous_df)[1:length(colnames(continuous_df)) - 1]) {
# Perform the t-test.
t_res <- t.test(continuous_df[continuous_df$diabetes == 1, colnames(continuous_df) == i],
continuous_df[continuous_df$diabetes == 0, colnames(continuous_df) == i])
# Collect results into a list.
entry <- list('col_name' = i,
'p_value' = t_res$p.value,
'diabetic_mean' = round(t_res$estimate[[1]],2),
'non_diabetic_mean' = round(t_res$estimate[[2]], 2))
# Add the entry into a list.
t_test_df[[i]] <- entry
}
# R-bind all lists to form a dataframe.
t_test_df <- rbindlist(t_test_df) %>%
arrange(p_value) %>%
mutate(significant = case_when(p_value < 0.05 ~ T,
T ~ F))
t_test_df
# Obtain categorical variables and gh.
query <- 'SELECT sex, re, income, tx, dx, gh FROM diabetes_data'
categorical_df <- dbGetQuery(conn, query) %>%
mutate(diabetes = case_when(gh >= 6.5 ~ T,
T ~ F)) %>%
select(-gh)
# Initialize empty list.
chi_sq_df <- list()
# For all columns except the diabetes marker, perform chi square test.
# Determine if variable in question is significantly associated with diabetes.
for (i in colnames(categorical_df)[1:length(colnames(categorical_df)) - 1]) {
# Construct contingency table, perform chi square test.
cont_table <- table(categorical_df[[i]], categorical_df$diabetes)
chi_squared_result <- chisq.test(cont_table)
cramers_v_result <- assocstats(cont_table)
# Store result in a list.
entry <- list('col_name' = i,
'chi-sq_stat' = chi_squared_result$statistic,
'p_value' = chi_squared_result$p.value,
'cramers_v' = cramers_v_result$cramer)
chi_sq_df[[i]] <- entry
}
# R-bind all lists to form a dataframe.
chi_sq_df <- rbindlist(chi_sq_df) %>%
arrange(p_value) %>%
mutate(significant = case_when(p_value < 0.05 ~ T,
T ~ F))
chi_sq_df
# Load data.
query <- 'SELECT * FROM diabetes_data'
df <- dbGetQuery(conn, query)
dbDisconnect(conn) # SQL is no longer used after this.
# Perform KNN imputation.
after_impute_df <- df %>%
kNN(variable = 'albumin',
k = 5) %>%
rename('albumin_imputed' = albumin_imp)
# Plot new distribution.
alb_after_plot <- ggplot(after_impute_df) +
geom_point(aes(x = albumin, y = gh, col = albumin_imputed))
alb_after_plot
print(paste('albumin NA values before imputation:', sum(is.na(df$albumin))))
print(paste('albumin NA values after imputation:', sum(is.na(after_impute_df$albumin))))
summary(df$albumin)
summary(after_impute_df$albumin)
after_impute_df <- after_impute_df %>%
select(age, bmi, albumin, tx, dx, gh) %>%
mutate(diabetes = case_when(gh >= 6.5 ~ 1,
T ~ 0),
diabetes = as.factor(diabetes)) %>%
select(-gh)
# Count number of rows after imputation.
print(paste('Total number of rows:', nrow(after_impute_df)))
# Filter out individuals below the age of 20.
after_impute_df_filtered <- after_impute_df %>%
filter(age > 20)
# Count number of rows after filtration.
print(paste('Total number of rows:', nrow(after_impute_df_filtered)))
# Split dataset in a 70:30 train:test ratio.
split <- sample.split(after_impute_df_filtered, SplitRatio = 0.7)
train_df <- subset(after_impute_df_filtered, split == T)
test_df <- subset(after_impute_df_filtered, split == F)
# Construct control variable for log regression model, for k-fold cross validation.
log_control <- trainControl(method = 'cv', number = 10)
# Build a logistic regression model.
log_model <- train(diabetes ~ ., data = train_df, method = "glm", family = "binomial", trControl = log_control)
log_model
# Collect results of model's coefficients and exponentiated coefficients in a dataframe.
coeffs <- rbind(
log_model$finalModel$coefficients,
exp(log_model$finalModel$coefficients)
) %>%
round(.,4) %>%
cbind(value = c('coefficient', 'exponentiated_coefficient')) %>%
as.data.frame()
coeffs
# Use model on test data.
log_predictions <- predict(log_model,
newdata = test_df)
log_results <- confusionMatrix(log_predictions, test_df$diabetes, positive = '1')
# Optimize cp value for decision trees.
control <- trainControl(method = "repeatedcv",
number = 10,
search = "grid")
decision_tree <- train(diabetes ~ ., data = train_df, 'rpart', trControl = control)
decision_tree
# Visualize the optimized model.
rpart.plot(decision_tree$finalModel)
# Use the model to predict diabetic labels.
decision_tree_predictions <- predict(decision_tree, newdata = test_df)
tree_results <- confusionMatrix(decision_tree_predictions,
test_df$diabetes,
positive = '1')
# Create and visualize a more complex tree. Use rpart to manually specify cp value
decision_tree_low_cp <- rpart(diabetes ~ ., data = train_df, cp = 0.0036)
rpart.plot(decision_tree_low_cp)
# Create random forest model.
rf <- train(diabetes ~ .,
data = train_df,
method = 'rf',
trControl = control)
rf
# Take the mean of all error rates, multiply by 100.
paste('Out of bag estimate of error rate:',
round(mean(rf$finalModel$err.rate[,1]), 2)*100,
'%',
sep = ' ')
# Use the model to make predictions on diabetic labels.
rf_predictions <- predict(rf, test_df)
rf_predictions <- as.factor(rf_predictions)
rf_results <- confusionMatrix(rf_predictions, test_df$diabetes, positive = '1')
# Result compilation.
# Bind all results into a dataframe.
combined_results <- rbind(
'Logistic regression' = unlist(log_results),
'Decision tree' = unlist(tree_results),
'Random forest' = unlist(rf_results)
) %>%
as.data.frame() %>%
# Remove all column prefixes.
# ^[^.]+ From the start of the string, detect any number of characters that is not a full stop.
# \\. Match a fullstop (\\ is used to escape the fullstop).
rename_all( ~ gsub("^[^.]+\\.", "", .)) %>%
# Select relevant columns.
select(Accuracy,
Sensitivity,
Specificity,
Precision,
`Neg Pred Value`,
F1) %>%
# Convert values from character to float (double), round to 4 digits after decimal points.
mutate_all(as.double) %>%
round(., 4) %>%
gt()
combined_results
